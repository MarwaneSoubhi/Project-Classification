# Project-Classification

# ğŸ“Š Telecom Churn Prediction using Machine Learning

## ğŸ” Project Overview
This project aims to predict **customer churn** for a telecom company using **Machine Learning models**. We compared **Logistic Regression, Random Forest, and Support Vector Machine (SVM)** to determine the best model for identifying customers at risk of leaving.

### ğŸ¯ **Objective**
- Develop a **classification model** to predict whether a customer will **churn** or **stay**.
- Compare **different machine learning models** to determine the most effective one.
- Use **feature selection and hyperparameter tuning** to improve accuracy.

---

## ğŸ“ **Dataset**
- ğŸ“‚ **Dataset Name:** `churn_data.csv`
- ğŸ”¢ **Target Variable:** `Churn Value` (0 = No Churn, 1 = Churn)
- ğŸ“Š **Key Features Used:**
  - `Tenure Months` (Customer duration)
  - `Monthly Charges`
  - `Total Charges`
  - `Contract Type`
  - `Internet Service Type`
  - `Payment Method`
  - `Tech Support`
  - `Online Security`

---

## ğŸ† **Best Model: Support Vector Machine (SVM)**
After training and evaluating **Logistic Regression, Random Forest, and SVM**, the **SVM model performed the best**, achieving:
- âœ… **Highest accuracy**
- âœ… **Better balance between Precision & Recall**
- âœ… **Higher ROC-AUC score**

---

## ğŸ›  **Machine Learning Workflow**
### **1ï¸âƒ£ Exploratory Data Analysis (EDA)**
- Checked for missing values and outliers.
- Dropped irrelevant columns (`Customer ID`, `Zip Code`, etc.).
- Visualized **feature correlations** using a **heatmap**.

### **2ï¸âƒ£ Data Preprocessing**
- **Encoded categorical variables** using `OneHotEncoder`.
- **Scaled numerical features** using `StandardScaler`.
- **Split data into training (80%) & testing (20%) sets**.

### **3ï¸âƒ£ Model Training & Comparison**
| Model | Accuracy | Recall (Churn) | Precision (Churn) | AUC Score |
|--------|----------|----------------|-------------------|------------|
| **Logistic Regression** | 74% | 78% | 51% | 0.848 |
| **Random Forest** | 77% | 75% | 55% | 0.85 |
| **SVM (Final Model)** | **79%** | **80%** | **58%** | **0.86** |

### **4ï¸âƒ£ Hyperparameter Tuning**
- Used `GridSearchCV` to optimize:
  - `C` (regularization parameter)
  - `kernel` (`linear` vs. `rbf`)
  - `gamma` (`scale` vs. `auto`)
- The final SVM model had:
  ```python
  best_params_ = {'C': 9.5, 'kernel': 'rbf', 'gamma': 'scale'}
